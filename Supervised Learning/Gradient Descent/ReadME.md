# The Gradient Descent Algorithm
![image](https://user-images.githubusercontent.com/95150718/145144537-9f51d5b5-d5d6-4ea6-b2e2-4c1d1cc0c05d.png)

## What is Gradient Descent?

Gradient descent (GD) is an iterative first-order optimisation algorithm used to find a local minimum/maximum of a given function. This method is commonly used in machine learning (ML) and deep learning(DL) to minimise a cost/loss function (e.g. in a linear regression).


## Gradient descent algorithm and its three types
![image](https://user-images.githubusercontent.com/95150718/145144925-678977f0-a88a-417b-bf16-e648997e8d97.png)

## How Gradient Descent work?
Gradient descent is an iterative optimization algorithm for finding the local minimum of a function.The objective in the case of gradient descent is to find a line of best fit for some given features (inputs), or X values, and any number of labels (outputs) or Y values
![image](https://user-images.githubusercontent.com/95150718/145145136-91b69e95-4568-444f-b0e7-381f6cb2a7ca.png)


## Minimizing the Cost Function
It is always the primary goal of any Machine Learning Algorithm to minimize the Cost Function. 
Minimizing cost functions will also result in a lower error between the predicted values and the actual values which also denotes that the algorithm has performed well in learning. 

 In order to minimize the function, we  use the Gradient Descent algorithm to locate the minima. The most common function which is often used is the  **mean squared error**. It measures the difference between the estimated value (the prediction) and the estimator (the dataset).
 ![](https://d2o2utebsixu4k.cloudfront.net/media/images/1566459128498-Image-33.jpg)
